---
title: "Classification with KNN and Logistic Regression"
author: "Praharsha Gangadhara"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(class)
library(e1071)
library(pROC)
```

## Load the Data

We begin by loading the dataset `UniversalBank.csv`. This dataset includes demographic and financial information about bank customers, along with whether they accepted a personal loan offer.

```{r}
bank_data <- read.csv("C:/Users/praha/Downloads/UniversalBank.csv")
str(bank_data)
```

## Data Cleaning

We remove non-informative variables (`ID` and `ZIP.Code`) that will not help in prediction. We also convert `Personal.Loan` to a factor so that it can be used in classification models.

```{r}
# Remove ID and Zip Code
bank_data <- bank_data[, !(names(bank_data) %in% c("ID", "ZIP.Code"))]

# Convert Personal Loan to factor
bank_data$Personal.Loan <- factor(bank_data$Personal.Loan)

# Check for missing values
sum(is.na(bank_data))
```

## Partitioning the Data

We split the dataset into training (70%) and testing (30%) sets. This allows us to train the models on one part of the data and evaluate how well they generalize on unseen data.

```{r}
set.seed(123)
train_index <- createDataPartition(bank_data$Personal.Loan, p = 0.7, list = FALSE)
train_data <- bank_data[train_index, ]
test_data <- bank_data[-train_index, ]
```

## Preprocessing for KNN

KNN is a distance-based algorithm and sensitive to the scale of the variables. Therefore, we normalize the features using centering and scaling.

```{r}
# Normalize features
preproc <- preProcess(train_data[, -which(names(train_data) == "Personal.Loan")], method = c("center", "scale"))
train_knn <- predict(preproc, train_data[, -which(names(train_data) == "Personal.Loan")])
test_knn <- predict(preproc, test_data[, -which(names(train_data) == "Personal.Loan")])

# Add target back
train_knn$Personal.Loan <- train_data$Personal.Loan
test_knn$Personal.Loan <- test_data$Personal.Loan
```

## Logistic Regression Model with Cross-Validation

We fit a logistic regression model using 10-fold cross-validation to evaluate its generalization performance. Logistic regression estimates the probability that a customer will accept a personal loan.

```{r}
set.seed(123)
ctrl <- trainControl(method = "cv", number = 10)
log_model <- train(Personal.Loan ~ ., data = train_data,
                   method = "glm", family = "binomial", trControl = ctrl)
summary(log_model)
```

## KNN Model with Cross-Validation

We use KNN to classify whether a customer accepts the loan. The model is trained and validated using 10-fold cross-validation, tuning over several values of K to find the best performing one.

```{r}
set.seed(123)
knn_model <- train(Personal.Loan ~ ., data = train_knn,
                   method = "knn", trControl = ctrl,
                   tuneLength = 10)
plot(knn_model)
```

## Model Evaluation on Test Set

We now use both trained models to make predictions on the test dataset. We evaluate model performance using a confusion matrix which provides accuracy and other statistics like precision, recall, and F1-score.

```{r}
# Logistic predictions
log_preds <- predict(log_model, newdata = test_data)
confusionMatrix(log_preds, test_data$Personal.Loan)

# KNN predictions
knn_preds <- predict(knn_model, newdata = test_knn)
confusionMatrix(knn_preds, test_knn$Personal.Loan)
```

## ROC Curve Comparison

We further compare the models using ROC curves and compute AUC (Area Under the Curve). A higher AUC indicates a better model in distinguishing between customers who accepted and didn't accept the loan.

```{r}
log_probs <- predict(log_model, newdata = test_data, type = "prob")[,2]
knn_probs <- predict(knn_model, newdata = test_knn, type = "prob")[,2]

log_roc <- roc(test_data$Personal.Loan, log_probs)
knn_roc <- roc(test_knn$Personal.Loan, knn_probs)

plot(log_roc, col = "blue", main = "ROC Curves")
lines(knn_roc, col = "red")
legend("bottomright", legend = c("Logistic", "KNN"), col = c("blue", "red"), lty = 1)
```
